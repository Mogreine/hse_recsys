{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Матричные факторизации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данной работе вам предстоит познакомиться с практической стороной матричных разложений.\n",
    "Работа поделена на 4 задания:\n",
    "1. Вам необходимо реализовать SVD разложения используя SGD на explicit данных\n",
    "2. Вам необходимо реализовать матричное разложения используя ALS на implicit данных\n",
    "3. Вам необходимо реализовать матричное разложения используя BPR на implicit данных\n",
    "4. Вам необходимо реализовать матричное разложения используя WARP на implicit данных\n",
    "\n",
    "Мягкий дедлайн 13 Октября (пишутся замечания, выставляется оценка, есть возможность исправить до жесткого дедлайна)\n",
    "\n",
    "Жесткий дедлайн 20 Октября (Итоговая проверка)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import implicit\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "\n",
    "from lightfm.datasets import fetch_movielens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данной работе мы будем работать с explicit датасетом movieLens, в котором представленны пары user_id movie_id и rating выставленный пользователем фильму\n",
    "\n",
    "Скачать датасет можно по ссылке https://grouplens.org/datasets/movielens/1m/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.read_csv('../data/ml-1m/ratings.dat', delimiter='::', header=None, \n",
    "        names=['user_id', 'movie_id', 'rating', 'timestamp'], \n",
    "        usecols=['user_id', 'movie_id', 'rating'], engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_info = pd.read_csv('../data/ml-1m/movies.dat', delimiter='::', header=None, \n",
    "        names=['movie_id', 'name', 'category'], engine='python')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explicit данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>914</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1197</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1287</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>2804</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>594</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>919</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  movie_id  rating\n",
       "0        1      1193       5\n",
       "1        1       661       3\n",
       "2        1       914       3\n",
       "3        1      3408       4\n",
       "4        1      2355       5\n",
       "5        1      1197       3\n",
       "6        1      1287       5\n",
       "7        1      2804       5\n",
       "8        1       594       4\n",
       "9        1       919       4"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для того, чтобы преобразовать текущий датасет в Implicit, давайте считать что позитивная оценка это оценка >=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "implicit_ratings = ratings.loc[(ratings['rating'] >= 4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1287</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>2804</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>594</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>919</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>595</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>938</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>2398</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    user_id  movie_id  rating\n",
       "0         1      1193       5\n",
       "3         1      3408       4\n",
       "4         1      2355       5\n",
       "6         1      1287       5\n",
       "7         1      2804       5\n",
       "8         1       594       4\n",
       "9         1       919       4\n",
       "10        1       595       5\n",
       "11        1       938       4\n",
       "12        1      2398       4"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "implicit_ratings.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удобнее работать с sparse матричками, давайте преобразуем DataFrame в CSR матрицы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = implicit_ratings[\"user_id\"]\n",
    "movies = implicit_ratings[\"movie_id\"]\n",
    "user_item = sp.coo_matrix((np.ones_like(users), (users, movies)))\n",
    "user_item_t_csr = user_item.T.tocsr()\n",
    "user_item_csr = user_item.tocsr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве примера воспользуемся ALS разложением из библиотеки implicit\n",
    "\n",
    "Зададим размерность латентного пространства равным 64, это же определяет размер user/item эмбедингов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Intel MKL BLAS detected. Its highly recommend to set the environment variable 'export MKL_NUM_THREADS=1' to disable its internal multithreading\n"
     ]
    }
   ],
   "source": [
    "model = implicit.als.AlternatingLeastSquares(factors=64, iterations=100, calculate_training_loss=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве loss здесь всеми любимый RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e466744b30a44e7b736e5cf9b829961",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.fit(user_item_t_csr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим похожие фильмы по 1 movie_id = Истории игрушек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>name</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Animation|Children's|Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children's|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Comedy|Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movie_id                                name                      category\n",
       "0         1                    Toy Story (1995)   Animation|Children's|Comedy\n",
       "1         2                      Jumanji (1995)  Adventure|Children's|Fantasy\n",
       "2         3             Grumpier Old Men (1995)                Comedy|Romance\n",
       "3         4            Waiting to Exhale (1995)                  Comedy|Drama\n",
       "4         5  Father of the Bride Part II (1995)                        Comedy"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_info.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_similars = lambda item_id, model : [movie_info[movie_info[\"movie_id\"] == x[0]][\"name\"].to_string() \n",
    "                                        for x in model.similar_items(item_id)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как мы видим, симилары действительно оказались симиларами.\n",
    "\n",
    "Качество симиларов часто является хорошим способом проверить качество алгоритмов.\n",
    "\n",
    "P.S. Если хочется поглубже разобраться в том как разные алгоритмы формируют разные латентные пространства, рекомендую загружать полученные вектора в tensorBoard и смотреть на сформированное пространство"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0    Toy Story (1995)',\n",
       " '3045    Toy Story 2 (1999)',\n",
       " \"2286    Bug's Life, A (1998)\",\n",
       " '33    Babe (1995)',\n",
       " '584    Aladdin (1992)',\n",
       " '2315    Babe: Pig in the City (1998)',\n",
       " '1838    Mulan (1998)',\n",
       " '1526    Hercules (1997)',\n",
       " '2618    Tarzan (1999)',\n",
       " '2692    Iron Giant, The (1999)']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_similars(1, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте теперь построим рекомендации для юзеров\n",
    "\n",
    "Как мы видим юзеру нравится фантастика, значит и в рекомендациях ожидаем увидеть фантастику"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_user_history = lambda user_id, implicit_ratings : [movie_info[movie_info[\"movie_id\"] == x][\"name\"].to_string() \n",
    "                                            for x in implicit_ratings[implicit_ratings[\"user_id\"] == user_id][\"movie_id\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3399    Hustler, The (1961)',\n",
       " '2882    Fistful of Dollars, A (1964)',\n",
       " '1196    Alien (1979)',\n",
       " '1023    Die Hard (1988)',\n",
       " '257    Star Wars: Episode IV - A New Hope (1977)',\n",
       " '1959    Saving Private Ryan (1998)',\n",
       " '476    Jurassic Park (1993)',\n",
       " '1180    Raiders of the Lost Ark (1981)',\n",
       " '1885    Rocky (1976)',\n",
       " '1081    E.T. the Extra-Terrestrial (1982)',\n",
       " '3349    Thelma & Louise (1991)',\n",
       " '3633    Mad Max (1979)',\n",
       " '2297    King Kong (1933)',\n",
       " '1366    Jaws (1975)',\n",
       " '1183    Good, The Bad and The Ugly, The (1966)',\n",
       " '2623    Run Lola Run (Lola rennt) (1998)',\n",
       " '2878    Goldfinger (1964)',\n",
       " '1220    Terminator, The (1984)']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_user_history(4, implicit_ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получилось! \n",
    "\n",
    "Мы действительно порекомендовали пользователю фантастику и боевики, более того встречаются продолжения тех фильмов, которые он высоко оценил"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_recommendations = lambda user_id, model : [movie_info[movie_info[\"movie_id\"] == x[0]][\"name\"].to_string() \n",
    "                                               for x in model.recommend(user_id, user_item_csr)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['585    Terminator 2: Judgment Day (1991)',\n",
       " '1271    Indiana Jones and the Last Crusade (1989)',\n",
       " '1182    Aliens (1986)',\n",
       " '1284    Butch Cassidy and the Sundance Kid (1969)',\n",
       " '2502    Matrix, The (1999)',\n",
       " '1178    Star Wars: Episode V - The Empire Strikes Back...',\n",
       " '1892    Rain Man (1988)',\n",
       " '3402    Close Encounters of the Third Kind (1977)',\n",
       " '1179    Princess Bride, The (1987)',\n",
       " '847    Godfather, The (1972)']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_recommendations(4, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь ваша очередь реализовать самые популярные алгоритмы матричных разложений\n",
    "\n",
    "Что будет оцениваться:\n",
    "1. Корректность алгоритма\n",
    "2. Качество получившихся симиларов\n",
    "3. Качество итоговых рекомендаций для юзера"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import time\n",
    "import implicit\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "\n",
    "from typing import Tuple, List\n",
    "from lightfm.datasets import fetch_movielens\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.special import expit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# util functions\n",
    "def time_it(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start = time.time()\n",
    "        func(*args, **kwargs)\n",
    "        return time.time() - start\n",
    "\n",
    "    return wrapper\n",
    "\n",
    "def calc_auc(model, R):\n",
    "    R = R.toarray()\n",
    "    auc = 0\n",
    "    for u_id, u in enumerate(R):\n",
    "        if np.count_nonzero(u != 0) == 0:\n",
    "            continue\n",
    "\n",
    "        pos_mask = u > 0\n",
    "        neg_mask = ~u\n",
    "\n",
    "        preds = model.I @ model.U[u_id]\n",
    "        comp_matrix = preds[pos_mask].reshape(-1, 1) > preds[neg_mask]\n",
    "        u_auc = np.count_nonzero(comp_matrix) / (comp_matrix.shape[0] * comp_matrix.shape[1])\n",
    "\n",
    "        auc += u_auc\n",
    "\n",
    "    return auc / R.shape[0]\n",
    "\n",
    "\n",
    "def test_model(model, implicit_ratings, movie_info):\n",
    "    get_similars = lambda item_id, model: [\n",
    "        movie_info[movie_info[\"movie_id\"] == x][\"name\"].to_string() for x in model.similar_items(item_id)\n",
    "    ]\n",
    "    print(\"Similars:\")\n",
    "    for r in get_similars(1, model): \n",
    "        print(r)\n",
    "\n",
    "    get_user_history = lambda user_id, implicit_ratings: [\n",
    "        movie_info[movie_info[\"movie_id\"] == x][\"name\"].to_string()\n",
    "        for x in implicit_ratings[implicit_ratings[\"user_id\"] == user_id][\"movie_id\"]\n",
    "    ]\n",
    "    \n",
    "    print(\"User's history:\")\n",
    "    for f in get_user_history(4, implicit_ratings):\n",
    "        print(f)\n",
    "\n",
    "    get_recommendations = lambda user_id, model: [\n",
    "        movie_info[movie_info[\"movie_id\"] == x][\"name\"].to_string() for x in model.recommend(user_id)\n",
    "    ]\n",
    "    \n",
    "    print(\"Recommendations:\")\n",
    "    for r in get_recommendations(4, model): \n",
    "        print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatrixFactorization:\n",
    "    def __init__(self, lr: float = 0.01, l2: float = 0.01):\n",
    "        self.lr = lr\n",
    "        self.l2 = l2\n",
    "\n",
    "        self.I = np.ndarray\n",
    "        self.U = np.ndarray\n",
    "\n",
    "    def _calc_metrics(self, R) -> Tuple[float, float]:\n",
    "        R = R.toarray()\n",
    "        non_zero_mask = R != 0\n",
    "        scores = self.U @ self.I.T\n",
    "        mse = np.sum((R[non_zero_mask] - scores[non_zero_mask]) ** 2)\n",
    "        rmse = np.sqrt(mse / np.count_nonzero(non_zero_mask))\n",
    "        reg = self.l2 * (np.sum(np.linalg.norm(self.I, axis=1) ** 2) + np.sum(np.linalg.norm(self.U, axis=1) ** 2))\n",
    "\n",
    "        return mse + reg, rmse\n",
    "\n",
    "    def _print_info(\n",
    "        self,\n",
    "        R,\n",
    "        step,\n",
    "        iteration_time,\n",
    "        verbose,\n",
    "        use_auc=False,\n",
    "        print_every=1,\n",
    "    ):\n",
    "        if verbose and step % print_every == 0:\n",
    "            loss, rmse = self._calc_metrics(R)\n",
    "            res_str = f\"Iteration: {step + 1}; time: {iteration_time:.1f}; loss: {loss:.2f}; rmse: {rmse: .5f}\"\n",
    "            if use_auc:\n",
    "                res_str += f\"; AUC: {calc_auc(self, R): .3f}\"\n",
    "            print(res_str)\n",
    "\n",
    "    def _initialize_matrix(self, n_users, n_items, hidden_dim):\n",
    "        self.U = np.random.uniform(0, 1 / np.sqrt(hidden_dim), size=(n_users, hidden_dim))\n",
    "        self.I = np.random.normal(0, 1 / np.sqrt(hidden_dim), size=(n_items, hidden_dim))\n",
    "\n",
    "    def recommend(self, user_id: int, n: int = 10):\n",
    "        scores = self.I @ self.U[user_id]\n",
    "        return np.argsort(-scores)[:n]\n",
    "\n",
    "    def similar_items(self, item_id: int, n: int = 10):\n",
    "        scores = cosine_similarity(self.I)\n",
    "        return np.argsort(-scores[item_id])[:n]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 1. Не использую готовые решения, реализовать SVD разложение используя SGD на explicit данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVD(MatrixFactorization):\n",
    "    def fit(self, R, hidden_dim: int = 10, n_iters: int = 10, verbose: bool = True):\n",
    "        n_users, n_items = R.shape\n",
    "        self._initialize_matrix(n_users, n_items, hidden_dim)\n",
    "\n",
    "        samples = [(i, j, k) for i, j, k in zip(R.row, R.col, R.data)]\n",
    "\n",
    "        for step in range(n_iters):\n",
    "            iteration_time = self._update_matrix(samples)\n",
    "\n",
    "            self._print_info(R, step, iteration_time, verbose)\n",
    "\n",
    "    @time_it\n",
    "    def _update_matrix(self, samples: List[Tuple[int, int, int]]):\n",
    "        U, I = self.U, self.I\n",
    "        lr, l2 = self.lr, self.l2\n",
    "\n",
    "        shuffled_samples = np.random.permutation(samples)\n",
    "        for u_id, i_id, r in shuffled_samples:\n",
    "            error = U[u_id] @ I[i_id] - r\n",
    "            U[u_id] = U[u_id] - lr * 2 * (error * I[i_id] + l2 * U[u_id])\n",
    "            I[i_id] = I[i_id] - lr * 2 * (error * U[u_id] + l2 * I[i_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1; time: 16.2; loss: 840340.09; rmse:  0.91642\n",
      "Iteration: 2; time: 16.3; loss: 687646.32; rmse:  0.82892\n",
      "Similars:\n",
      "0    Toy Story (1995)\n",
      "1205    Grand Day Out, A (1992)\n",
      "1449    Love Jones (1997)\n",
      "3535    Gypsy (1962)\n",
      "2009    Jungle Book, The (1967)\n",
      "3045    Toy Story 2 (1999)\n",
      "2011    Lady and the Tramp (1955)\n",
      "3282    Two Thousand Maniacs! (1964)\n",
      "935    My Man Godfrey (1936)\n",
      "3175    Goodbye Girl, The (1977)\n",
      "User's history:\n",
      "3399    Hustler, The (1961)\n",
      "2882    Fistful of Dollars, A (1964)\n",
      "1196    Alien (1979)\n",
      "1023    Die Hard (1988)\n",
      "257    Star Wars: Episode IV - A New Hope (1977)\n",
      "1959    Saving Private Ryan (1998)\n",
      "476    Jurassic Park (1993)\n",
      "1180    Raiders of the Lost Ark (1981)\n",
      "1885    Rocky (1976)\n",
      "1081    E.T. the Extra-Terrestrial (1982)\n",
      "3349    Thelma & Louise (1991)\n",
      "3633    Mad Max (1979)\n",
      "2297    King Kong (1933)\n",
      "1366    Jaws (1975)\n",
      "1183    Good, The Bad and The Ugly, The (1966)\n",
      "2623    Run Lola Run (Lola rennt) (1998)\n",
      "2878    Goldfinger (1964)\n",
      "1220    Terminator, The (1984)\n",
      "Recommendations:\n",
      "604    Fargo (1996)\n",
      "910    Sunset Blvd. (a.k.a. Sunset Boulevard) (1950)\n",
      "711    Wallace & Gromit: The Best of Aardman Animatio...\n",
      "1194    Third Man, The (1949)\n",
      "2134    Shadow of a Doubt (1943)\n",
      "847    Godfather, The (1972)\n",
      "892    Rear Window (1954)\n",
      "3366    Double Indemnity (1944)\n",
      "1188    Clockwork Orange, A (1971)\n",
      "49    Usual Suspects, The (1995)\n"
     ]
    }
   ],
   "source": [
    "user_item_exp = sp.coo_matrix((ratings[\"rating\"], (ratings[\"user_id\"], ratings[\"movie_id\"])))\n",
    "\n",
    "svd = SVD(lr=0.01, l2=0.01)\n",
    "svd.fit(user_item_exp, n_iters=2, hidden_dim=64)\n",
    "\n",
    "test_model(svd, implicit_ratings, movie_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 2. Не использую готовые решения, реализовать матричное разложение используя ALS на implicit данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ALS(MatrixFactorization):\n",
    "    def fit(self, R, hidden_dim: int = 10, n_iters: int = 10, verbose: bool = True):\n",
    "        n_users, n_items = R.shape\n",
    "        self._initialize_matrix(n_users, n_items, hidden_dim)\n",
    "\n",
    "        for step in range(n_iters):\n",
    "            iteration_time = self._update_matrix(self.U, self.I, R, hidden_dim, True) + self._update_matrix(\n",
    "                self.I, self.U, R, hidden_dim, False\n",
    "            )\n",
    "\n",
    "            self._print_info(R, step, iteration_time, verbose)\n",
    "\n",
    "    @time_it\n",
    "    def _update_matrix(self, X, Y, R, hidden_dim, item: bool):\n",
    "        n_objects = X.shape[0]\n",
    "\n",
    "        # updating users\n",
    "        for i in range(n_objects):\n",
    "            if item:\n",
    "                r = R[i].toarray().flatten()\n",
    "            else:\n",
    "                r = R[:, i].toarray().flatten()\n",
    "\n",
    "            non_zero_ids_mask = r != 0\n",
    "            if np.count_nonzero(non_zero_ids_mask) == 0:\n",
    "                continue\n",
    "\n",
    "            ys = Y[non_zero_ids_mask]\n",
    "\n",
    "            # sum of outer products of y\n",
    "            outer_prods = Y.T @ Y\n",
    "            inv = np.eye(hidden_dim) * self.l2 + outer_prods\n",
    "            inv = np.linalg.inv(inv)\n",
    "\n",
    "            # sum of r * y\n",
    "            r_part = np.sum(r[non_zero_ids_mask].reshape(-1, 1) * ys, axis=0)\n",
    "\n",
    "            X[i] = inv @ r_part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1; time: 24.5; loss: 355073.01; rmse:  0.76690\n",
      "Iteration: 2; time: 23.5; loss: 277206.41; rmse:  0.67375\n",
      "Iteration: 3; time: 25.8; loss: 265931.31; rmse:  0.66064\n",
      "Iteration: 4; time: 28.0; loss: 261219.91; rmse:  0.65569\n",
      "Iteration: 5; time: 19.9; loss: 258550.29; rmse:  0.65312\n"
     ]
    }
   ],
   "source": [
    "als = ALS(l2=1)\n",
    "als.fit(user_item_csr, n_iters=5, hidden_dim=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similars:\n",
      "0    Toy Story (1995)\n",
      "3045    Toy Story 2 (1999)\n",
      "2286    Bug's Life, A (1998)\n",
      "584    Aladdin (1992)\n",
      "360    Lion King, The (1994)\n",
      "2252    Pleasantville (1998)\n",
      "2618    Tarzan (1999)\n",
      "33    Babe (1995)\n",
      "1838    Mulan (1998)\n",
      "1526    Hercules (1997)\n",
      "User's history:\n",
      "3399    Hustler, The (1961)\n",
      "2882    Fistful of Dollars, A (1964)\n",
      "1196    Alien (1979)\n",
      "1023    Die Hard (1988)\n",
      "257    Star Wars: Episode IV - A New Hope (1977)\n",
      "1959    Saving Private Ryan (1998)\n",
      "476    Jurassic Park (1993)\n",
      "1180    Raiders of the Lost Ark (1981)\n",
      "1885    Rocky (1976)\n",
      "1081    E.T. the Extra-Terrestrial (1982)\n",
      "3349    Thelma & Louise (1991)\n",
      "3633    Mad Max (1979)\n",
      "2297    King Kong (1933)\n",
      "1366    Jaws (1975)\n",
      "1183    Good, The Bad and The Ugly, The (1966)\n",
      "2623    Run Lola Run (Lola rennt) (1998)\n",
      "2878    Goldfinger (1964)\n",
      "1220    Terminator, The (1984)\n",
      "Recommendations:\n",
      "1180    Raiders of the Lost Ark (1981)\n",
      "257    Star Wars: Episode IV - A New Hope (1977)\n",
      "1366    Jaws (1975)\n",
      "1196    Alien (1979)\n",
      "1081    E.T. the Extra-Terrestrial (1982)\n",
      "1220    Terminator, The (1984)\n",
      "1959    Saving Private Ryan (1998)\n",
      "585    Terminator 2: Judgment Day (1991)\n",
      "1023    Die Hard (1988)\n",
      "2502    Matrix, The (1999)\n"
     ]
    }
   ],
   "source": [
    "test_model(als, implicit_ratings, movie_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 3. Не использую готовые решения, реализовать матричное разложение BPR на implicit данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BPR(MatrixFactorization):\n",
    "    def fit(self, R, hidden_dim: int = 10, n_iters: int = 10, batch_size: int = 32, verbose: bool = True):\n",
    "        n_users, n_items = R.shape\n",
    "        self._initialize_matrix(n_users, n_items, hidden_dim)\n",
    "\n",
    "        indptr = R.indptr\n",
    "        indices = R.indices\n",
    "        n_users, n_items = R.shape\n",
    "\n",
    "        for step in range(n_iters):\n",
    "            users, items_pos, items_neg = self._sample(n_users, n_items, batch_size, indices, indptr)\n",
    "            iteration_time = self._grad_step(users, items_pos, items_neg)\n",
    "\n",
    "            self._print_info(R, step, iteration_time, verbose, True, 100)\n",
    "\n",
    "    @time_it\n",
    "    def _grad_step(self, u, ii, ij):\n",
    "        user_u = self.U[u]\n",
    "        item_i = self.I[ii]\n",
    "        item_j = self.I[ij]\n",
    "\n",
    "        r_uij = np.sum(user_u * (item_i - item_j), axis=1)\n",
    "        sigmoid = np.exp(-r_uij) / (1.0 + np.exp(-r_uij))\n",
    "\n",
    "        hidden_dim = self.I.shape[1]\n",
    "        sigmoid_tiled = np.tile(sigmoid, (hidden_dim, 1)).T\n",
    "\n",
    "        grad_u = sigmoid_tiled * (item_j - item_i) + self.l2 * user_u\n",
    "        grad_i = sigmoid_tiled * -user_u + self.l2 * item_i\n",
    "        grad_j = sigmoid_tiled * user_u + self.l2 * item_j\n",
    "        self.U[u] -= self.lr * grad_u\n",
    "        self.I[ii] -= self.lr * grad_i\n",
    "        self.I[ij] -= self.lr * grad_j\n",
    "\n",
    "    def _sample(self, n_users, n_items, batch_size, indices, indptr):\n",
    "        \"\"\"sample batches of random triplets u, i, j\"\"\"\n",
    "        sampled_pos_items = np.zeros(batch_size, dtype=np.int)\n",
    "        sampled_neg_items = np.zeros(batch_size, dtype=np.int)\n",
    "        sampled_users = np.random.choice(n_users, size=batch_size, replace=False)\n",
    "\n",
    "        for idx, user in enumerate(sampled_users):\n",
    "            pos_items = indices[indptr[user] : indptr[user + 1]]\n",
    "\n",
    "            if len(pos_items) == 0:\n",
    "                continue\n",
    "\n",
    "            pos_item = np.random.choice(pos_items)\n",
    "            neg_item = np.random.choice(n_items)\n",
    "            while neg_item in pos_items:\n",
    "                neg_item = np.random.choice(n_items)\n",
    "\n",
    "            sampled_pos_items[idx] = pos_item\n",
    "            sampled_neg_items[idx] = neg_item\n",
    "\n",
    "        return sampled_users, sampled_pos_items, sampled_neg_items\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1; time: 0.0; loss: 579000.48; rmse:  1.00318; AUC:  0.510\n",
      "Iteration: 101; time: 0.0; loss: 556679.65; rmse:  0.98365; AUC:  0.600\n",
      "Iteration: 201; time: 0.0; loss: 536216.71; rmse:  0.96539; AUC:  0.682\n",
      "Iteration: 301; time: 0.0; loss: 520711.75; rmse:  0.95131; AUC:  0.694\n",
      "Iteration: 401; time: 0.0; loss: 524601.40; rmse:  0.95484; AUC:  0.725\n",
      "Iteration: 501; time: 0.0; loss: 568505.29; rmse:  0.99398; AUC:  0.686\n",
      "Iteration: 601; time: 0.0; loss: 669776.66; rmse:  1.07888; AUC:  0.689\n",
      "Iteration: 701; time: 0.0; loss: 844222.18; rmse:  1.21127; AUC:  0.806\n",
      "Iteration: 801; time: 0.0; loss: 1114748.90; rmse:  1.39190; AUC:  0.816\n",
      "Iteration: 901; time: 0.0; loss: 1496858.67; rmse:  1.61293; AUC:  0.818\n",
      "Iteration: 1001; time: 0.0; loss: 2015487.37; rmse:  1.87163; AUC:  0.775\n",
      "Iteration: 1101; time: 0.0; loss: 2689173.34; rmse:  2.16195; AUC:  0.798\n",
      "Iteration: 1201; time: 0.0; loss: 3535363.88; rmse:  2.47889; AUC:  0.824\n",
      "Iteration: 1301; time: 0.0; loss: 4563936.52; rmse:  2.81652; AUC:  0.809\n",
      "Iteration: 1401; time: 0.0; loss: 5786873.57; rmse:  3.17151; AUC:  0.843\n",
      "Iteration: 1501; time: 0.0; loss: 7199515.88; rmse:  3.53751; AUC:  0.804\n",
      "Iteration: 1601; time: 0.0; loss: 8833123.75; rmse:  3.91837; AUC:  0.765\n",
      "Iteration: 1701; time: 0.0; loss: 10650895.92; rmse:  4.30271; AUC:  0.877\n",
      "Iteration: 1801; time: 0.0; loss: 12697941.91; rmse:  4.69804; AUC:  0.871\n",
      "Iteration: 1901; time: 0.0; loss: 14912679.45; rmse:  5.09130; AUC:  0.894\n",
      "Iteration: 2001; time: 0.0; loss: 17303930.22; rmse:  5.48434; AUC:  0.883\n",
      "Iteration: 2101; time: 0.0; loss: 19834505.19; rmse:  5.87169; AUC:  0.911\n",
      "Iteration: 2201; time: 0.0; loss: 22519119.72; rmse:  6.25646; AUC:  0.915\n",
      "Iteration: 2301; time: 0.0; loss: 25264639.21; rmse:  6.62689; AUC:  0.879\n",
      "Iteration: 2401; time: 0.0; loss: 28112990.94; rmse:  6.99048; AUC:  0.904\n",
      "Iteration: 2501; time: 0.0; loss: 31091259.58; rmse:  7.35145; AUC:  0.876\n",
      "Iteration: 2601; time: 0.0; loss: 34129192.53; rmse:  7.70224; AUC:  0.854\n",
      "Iteration: 2701; time: 0.0; loss: 37274686.68; rmse:  8.04936; AUC:  0.927\n",
      "Iteration: 2801; time: 0.0; loss: 40450273.14; rmse:  8.38523; AUC:  0.930\n",
      "Iteration: 2901; time: 0.0; loss: 43685089.79; rmse:  8.71407; AUC:  0.895\n",
      "Iteration: 3001; time: 0.0; loss: 46960721.77; rmse:  9.03487; AUC:  0.933\n",
      "Iteration: 3101; time: 0.0; loss: 50247473.57; rmse:  9.34570; AUC:  0.912\n",
      "Iteration: 3201; time: 0.0; loss: 53634008.50; rmse:  9.65551; AUC:  0.882\n",
      "Iteration: 3301; time: 0.0; loss: 57007285.66; rmse:  9.95452; AUC:  0.926\n",
      "Iteration: 3401; time: 0.0; loss: 60447913.95; rmse:  10.25052; AUC:  0.923\n",
      "Iteration: 3501; time: 0.0; loss: 63845317.17; rmse:  10.53464; AUC:  0.931\n",
      "Iteration: 3601; time: 0.0; loss: 67294621.28; rmse:  10.81548; AUC:  0.931\n",
      "Iteration: 3701; time: 0.0; loss: 70730953.03; rmse:  11.08818; AUC:  0.922\n",
      "Iteration: 3801; time: 0.0; loss: 74116166.93; rmse:  11.35042; AUC:  0.873\n",
      "Iteration: 3901; time: 0.0; loss: 77642876.83; rmse:  11.61734; AUC:  0.921\n",
      "Iteration: 4001; time: 0.0; loss: 81123437.24; rmse:  11.87487; AUC:  0.922\n",
      "Iteration: 4101; time: 0.0; loss: 84582392.46; rmse:  12.12539; AUC:  0.904\n",
      "Iteration: 4201; time: 0.0; loss: 88066605.45; rmse:  12.37262; AUC:  0.921\n",
      "Iteration: 4301; time: 0.0; loss: 91437370.76; rmse:  12.60718; AUC:  0.906\n",
      "Iteration: 4401; time: 0.0; loss: 95039169.35; rmse:  12.85308; AUC:  0.933\n",
      "Iteration: 4501; time: 0.0; loss: 98413970.04; rmse:  13.07930; AUC:  0.912\n",
      "Iteration: 4601; time: 0.0; loss: 101880210.95; rmse:  13.30764; AUC:  0.907\n",
      "Iteration: 4701; time: 0.0; loss: 105257594.59; rmse:  13.52642; AUC:  0.923\n",
      "Iteration: 4801; time: 0.0; loss: 108525481.62; rmse:  13.73479; AUC:  0.912\n",
      "Iteration: 4901; time: 0.0; loss: 111827439.23; rmse:  13.94217; AUC:  0.908\n",
      "Iteration: 5001; time: 0.0; loss: 115082799.80; rmse:  14.14365; AUC:  0.932\n",
      "Iteration: 5101; time: 0.0; loss: 118428645.76; rmse:  14.34778; AUC:  0.946\n",
      "Iteration: 5201; time: 0.0; loss: 121640665.50; rmse:  14.54105; AUC:  0.947\n",
      "Iteration: 5301; time: 0.0; loss: 124903118.09; rmse:  14.73476; AUC:  0.919\n",
      "Iteration: 5401; time: 0.0; loss: 128062801.00; rmse:  14.91997; AUC:  0.926\n",
      "Iteration: 5501; time: 0.0; loss: 131236434.59; rmse:  15.10371; AUC:  0.925\n",
      "Iteration: 5601; time: 0.0; loss: 134329741.14; rmse:  15.28068; AUC:  0.933\n",
      "Iteration: 5701; time: 0.0; loss: 137417042.33; rmse:  15.45528; AUC:  0.930\n",
      "Iteration: 5801; time: 0.0; loss: 140462553.84; rmse:  15.62561; AUC:  0.930\n",
      "Iteration: 5901; time: 0.0; loss: 143482553.62; rmse:  15.79269; AUC:  0.938\n",
      "Iteration: 6001; time: 0.0; loss: 146369559.65; rmse:  15.95079; AUC:  0.933\n",
      "Iteration: 6101; time: 0.0; loss: 149302499.52; rmse:  16.10980; AUC:  0.938\n",
      "Iteration: 6201; time: 0.0; loss: 151969446.38; rmse:  16.25305; AUC:  0.931\n",
      "Iteration: 6301; time: 0.0; loss: 154955930.77; rmse:  16.41198; AUC:  0.941\n",
      "Iteration: 6401; time: 0.0; loss: 157653389.57; rmse:  16.55421; AUC:  0.945\n",
      "Iteration: 6501; time: 0.0; loss: 160239951.81; rmse:  16.68946; AUC:  0.932\n",
      "Iteration: 6601; time: 0.0; loss: 162876922.70; rmse:  16.82622; AUC:  0.927\n",
      "Iteration: 6701; time: 0.0; loss: 165422282.18; rmse:  16.95719; AUC:  0.939\n",
      "Iteration: 6801; time: 0.0; loss: 168042747.93; rmse:  17.09097; AUC:  0.933\n",
      "Iteration: 6901; time: 0.0; loss: 170509739.31; rmse:  17.21597; AUC:  0.945\n",
      "Iteration: 7001; time: 0.0; loss: 172869638.23; rmse:  17.33470; AUC:  0.937\n",
      "Iteration: 7101; time: 0.0; loss: 175405137.51; rmse:  17.46136; AUC:  0.935\n",
      "Iteration: 7201; time: 0.0; loss: 177701883.59; rmse:  17.57531; AUC:  0.927\n",
      "Iteration: 7301; time: 0.0; loss: 180053122.68; rmse:  17.69120; AUC:  0.938\n",
      "Iteration: 7401; time: 0.0; loss: 182395107.70; rmse:  17.80588; AUC:  0.929\n",
      "Iteration: 7501; time: 0.0; loss: 184694394.53; rmse:  17.91776; AUC:  0.914\n",
      "Iteration: 7601; time: 0.0; loss: 187061063.28; rmse:  18.03220; AUC:  0.926\n",
      "Iteration: 7701; time: 0.0; loss: 189377377.08; rmse:  18.14350; AUC:  0.930\n",
      "Iteration: 7801; time: 0.0; loss: 191512085.24; rmse:  18.24547; AUC:  0.918\n",
      "Iteration: 7901; time: 0.0; loss: 193526812.86; rmse:  18.34119; AUC:  0.948\n"
     ]
    }
   ],
   "source": [
    "bpr = BPR(lr=1e-2, l2=0.01)\n",
    "bpr.fit(user_item_csr, n_iters=8000, hidden_dim=64, batch_size=user_item_csr.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similars:\n",
      "0    Toy Story (1995)\n",
      "1446    Jungle2Jungle (a.k.a. Jungle 2 Jungle) (1997)\n",
      "565    Little Big League (1994)\n",
      "3045    Toy Story 2 (1999)\n",
      "370    Richie Rich (1994)\n",
      "2807    Thumbelina (1994)\n",
      "584    Aladdin (1992)\n",
      "3327    Muppet Movie, The (1979)\n",
      "1967    Blank Check (1994)\n",
      "2759    Dudley Do-Right (1999)\n",
      "User's history:\n",
      "3399    Hustler, The (1961)\n",
      "2882    Fistful of Dollars, A (1964)\n",
      "1196    Alien (1979)\n",
      "1023    Die Hard (1988)\n",
      "257    Star Wars: Episode IV - A New Hope (1977)\n",
      "1959    Saving Private Ryan (1998)\n",
      "476    Jurassic Park (1993)\n",
      "1180    Raiders of the Lost Ark (1981)\n",
      "1885    Rocky (1976)\n",
      "1081    E.T. the Extra-Terrestrial (1982)\n",
      "3349    Thelma & Louise (1991)\n",
      "3633    Mad Max (1979)\n",
      "2297    King Kong (1933)\n",
      "1366    Jaws (1975)\n",
      "1183    Good, The Bad and The Ugly, The (1966)\n",
      "2623    Run Lola Run (Lola rennt) (1998)\n",
      "2878    Goldfinger (1964)\n",
      "1220    Terminator, The (1984)\n",
      "Recommendations:\n",
      "1220    Terminator, The (1984)\n",
      "1183    Good, The Bad and The Ugly, The (1966)\n",
      "257    Star Wars: Episode IV - A New Hope (1977)\n",
      "1366    Jaws (1975)\n",
      "1180    Raiders of the Lost Ark (1981)\n",
      "1023    Die Hard (1988)\n",
      "2297    King Kong (1933)\n",
      "1885    Rocky (1976)\n",
      "1196    Alien (1979)\n",
      "2882    Fistful of Dollars, A (1964)\n"
     ]
    }
   ],
   "source": [
    "test_model(bpr, implicit_ratings, movie_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 4. Не использую готовые решения, реализовать матричное разложение WARP на implicit данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
